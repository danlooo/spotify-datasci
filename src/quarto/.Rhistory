[
Input(shape=(len(features),)),
Dense(100, activation="relu"),
Dropout(0.2),
Dense(100, activation="relu"),
Dense(train_Y_one_hot.shape[1], activation="softmax")
]
)
model2.build()
model2.compile(
optimizer=keras.optimizers.SGD(),
loss="categorical_crossentropy",
metrics=[keras.metrics.CategoricalAccuracy(), keras.metrics.TopKCategoricalAccuracy(k=2)]
)
model2.summary()
model2.fit(train_X, train_Y_one_hot, epochs = 100, verbose = 0,
validation_data=(test_X, test_Y_one_hot))
model2.evaluate(test_X, test_Y_one_hot)
r.c_pitches.merge(r.track_train_test_split)
data
data = r.c_pitches.merge(r.track_train_test_split)
data
data.query("is_train")
data.query("is_train").drop("is_train")
data.query("is_train").drop("is_train")
data.query("is_train").drop(columns = "is_train")
data.query("is_train").drop(columns = "is_train").set_index("id")
data = r.c_pitches.merge(r.track_train_test_split).set_index("id")
train_X = data.query("is_train").drop(columns = "is_train")
data = r.c_pitches.merge(r.track_train_test_split).set_index("id")
train_X = data.query("is_train").drop(columns = "is_train")
test_X = data.query("not is_train").drop(columns = "is_train")
train_X
train_X.shape[1]
data = r.c_pitches.merge(r.track_train_test_split).set_index("id")
train_X = data.query("is_train").drop(columns = "is_train")
test_X = data.query("not is_train").drop(columns = "is_train")
from keras.layers import Conv1D
random.seed(1337)
model2 = keras.Sequential(
[
Input(100, kernel_size=80, shape=(train_X.shape[1],)),
Conv1D(activation = "relu"),
Dense(train_Y_one_hot.shape[1], activation="softmax")
]
)
model2.build()
model2.compile(
optimizer=keras.optimizers.SGD(),
loss="categorical_crossentropy",
metrics=[keras.metrics.CategoricalAccuracy(), keras.metrics.TopKCategoricalAccuracy(k=2)]
)
model2.summary()
model2.fit(train_X, train_Y_one_hot, epochs = 100, verbose = 0, validation_data=(test_X, test_Y_one_hot))
data = r.c_pitches.merge(r.track_train_test_split).set_index("id")
train_X = data.query("is_train").drop(columns = "is_train")
test_X = data.query("not is_train").drop(columns = "is_train")
from keras.layers import Conv1D
random.seed(1337)
model2 = keras.Sequential(
[
Input(shape=(train_X.shape[1],)),
Conv1D(100, kernel_size=80, activation = "relu"),
Dense(train_Y_one_hot.shape[1], activation="softmax")
]
)
model2.build()
model2.compile(
optimizer=keras.optimizers.SGD(),
loss="categorical_crossentropy",
metrics=[keras.metrics.CategoricalAccuracy(), keras.metrics.TopKCategoricalAccuracy(k=2)]
)
model2.summary()
model2.fit(train_X, train_Y_one_hot, epochs = 100, verbose = 0, validation_data=(test_X, test_Y_one_hot))
data = r.c_pitches.merge(r.track_train_test_split).set_index("id")
train_X = data.query("is_train").drop(columns = "is_train")
test_X = data.query("not is_train").drop(columns = "is_train")
from keras.layers import Conv1D
random.seed(1337)
model2 = keras.Sequential(
[
Input(shape=(train_X.shape[1],)),
Conv1D(100, kernel_size=80, activation = "relu"),
Dense(train_Y_one_hot.shape[1], activation="softmax")
]
)
model2.build()
model2.compile(
optimizer=keras.optimizers.SGD(),
loss="categorical_crossentropy",
metrics=[keras.metrics.CategoricalAccuracy(), keras.metrics.TopKCategoricalAccuracy(k=2)]
)
data = r.c_pitches.merge(r.track_train_test_split).set_index("id")
train_X = data.query("is_train").drop(columns = "is_train")
test_X = data.query("not is_train").drop(columns = "is_train")
from keras.layers import Conv1D
random.seed(1337)
model2 = keras.Sequential(
[
Conv1D(800, kernel_size=80, activation = "relu"),
Dense(train_Y_one_hot.shape[1], activation="softmax")
]
)
model2.build()
model2.compile(
optimizer=keras.optimizers.SGD(),
loss="categorical_crossentropy",
metrics=[keras.metrics.CategoricalAccuracy(), keras.metrics.TopKCategoricalAccuracy(k=2)]
)
model2.summary()
model2.fit(train_X, train_Y_one_hot, epochs = 100, verbose = 0, validation_data=(test_X, test_Y_one_hot))
data = r.c_pitches.merge(r.track_train_test_split).set_index("id")
train_X = data.query("is_train").drop(columns = "is_train")
test_X = data.query("not is_train").drop(columns = "is_train")
from keras.layers import Conv1D
random.seed(1337)
model2 = keras.Sequential(
[
Input(shape=(train_X.shape[1],)),
#Conv1D(100, kernel_size=80, activation = "relu"),
Dense(100, activation = "relu"),
Dense(train_Y_one_hot.shape[1], activation="softmax")
]
)
model2.build()
model2.compile(
optimizer=keras.optimizers.SGD(),
loss="categorical_crossentropy",
metrics=[keras.metrics.CategoricalAccuracy(), keras.metrics.TopKCategoricalAccuracy(k=2)]
)
model2.summary()
model2.fit(train_X, train_Y_one_hot, epochs = 100, verbose = 0, validation_data=(test_X, test_Y_one_hot))
data = r.c_pitches.merge(r.track_train_test_split).set_index("id")
train_X = data.query("is_train").drop(columns = "is_train")
test_X = data.query("not is_train").drop(columns = "is_train")
from keras.layers import Conv1D
random.seed(1337)
model3 = keras.Sequential(
[
Input(shape=(train_X.shape[1],)),
#Conv1D(100, kernel_size=80, activation = "relu"),
Dense(100, activation = "relu"),
Dense(train_Y_one_hot.shape[1], activation="softmax")
]
)
model3.build()
model3.compile(
optimizer=keras.optimizers.SGD(),
loss="categorical_crossentropy",
metrics=[keras.metrics.CategoricalAccuracy(), keras.metrics.TopKCategoricalAccuracy(k=2)]
)
model3.summary()
model3.fit(train_X, train_Y_one_hot, epochs = 100, verbose = 0, validation_data=(test_X, test_Y_one_hot))
model3.evaluate(test_X, test_Y_one_hot)
data = r.c_pitches.merge(r.track_train_test_split).set_index("id")
train_X = data.query("is_train").drop(columns = "is_train")
test_X = data.query("not is_train").drop(columns = "is_train")
from keras.layers import Conv1D
random.seed(1337)
model3 = keras.Sequential(
[
Input(shape=(train_X.shape[1],)),
Conv1D(100, kernel_size=80, activation = "relu"),
Dense(100, activation = "relu"),
Dense(train_Y_one_hot.shape[1], activation="softmax")
]
)
model3.build()
model3.compile(
optimizer=keras.optimizers.SGD(),
loss="categorical_crossentropy",
metrics=[keras.metrics.CategoricalAccuracy(), keras.metrics.TopKCategoricalAccuracy(k=2)]
)
model3.summary()
model3.fit(train_X, train_Y_one_hot, epochs = 100, verbose = 0, validation_data=(test_X, test_Y_one_hot))
model3.evaluate(test_X, test_Y_one_hot)
data = r.c_pitches.merge(r.track_train_test_split).set_index("id")
train_X = data.query("is_train").drop(columns = "is_train")
test_X = data.query("not is_train").drop(columns = "is_train")
from keras.layers import Conv1D
random.seed(1337)
model3 = keras.Sequential(
[
Input(shape=(train_X.shape[1],1)),
Conv1D(100, kernel_size=80, activation = "relu"),
Dense(100, activation = "relu"),
Dense(train_Y_one_hot.shape[1], activation="softmax")
]
)
model3.build()
model3.compile(
optimizer=keras.optimizers.SGD(),
loss="categorical_crossentropy",
metrics=[keras.metrics.CategoricalAccuracy(), keras.metrics.TopKCategoricalAccuracy(k=2)]
)
model3.summary()
model3.fit(train_X, train_Y_one_hot, epochs = 100, verbose = 0, validation_data=(test_X, test_Y_one_hot))
model3.evaluate(test_X, test_Y_one_hot)
data = r.c_pitches.merge(r.track_train_test_split).set_index("id")
train_X = data.query("is_train").drop(columns = "is_train")
train_X = tf.expand_dims(train_X, axis=-1)
import tensorflow as tf
data = r.c_pitches.merge(r.track_train_test_split).set_index("id")
train_X = data.query("is_train").drop(columns = "is_train")
train_X = tf.expand_dims(train_X, axis=-1)
test_X = data.query("not is_train").drop(columns = "is_train")
train_X
import tensorflow as tf
from keras.layers import Conv1D
data = r.c_pitches.merge(r.track_train_test_split).set_index("id")
train_X = data.query("is_train").drop(columns = "is_train")
train_X = tf.expand_dims(train_X, axis=-1)
test_X = data.query("not is_train").drop(columns = "is_train")
test_X = tf.expand_dims(test_X, axis=-1)
random.seed(1337)
model3 = keras.Sequential(
[
Input(shape=(train_X.shape[1],1)),
Conv1D(100, kernel_size=80, activation = "relu"),
Dense(100, activation = "relu"),
Dense(train_Y_one_hot.shape[1], activation="softmax")
]
)
model3.build()
model3.compile(
optimizer=keras.optimizers.SGD(),
loss="categorical_crossentropy",
metrics=[keras.metrics.CategoricalAccuracy(), keras.metrics.TopKCategoricalAccuracy(k=2)]
)
model3.summary()
model3.fit(train_X, train_Y_one_hot, epochs = 100, verbose = 0, validation_data=(test_X, test_Y_one_hot))
model3.evaluate(test_X, test_Y_one_hot)
model3.fit(train_X, train_Y_one_hot, epochs = 100, verbose = 0, validation_data=(test_X, test_Y_one_hot))
model3.summary()
train_X
train_X
train_X.shape
train_X.shape
data.query("is_train").drop(columns = "is_train")
data = r.c_pitches.merge(r.track_train_test_split).set_index("id")
train_X = data.query("is_train").drop(columns = "is_train")
data.query("is_train").drop(columns = "is_train")
train_X = data.query("is_train").drop(columns = "is_train")
train_X
tf.convert_to_tensor(train_X)
import tensorflow as tf
from keras.layers import Conv1D
data = r.c_pitches.merge(r.track_train_test_split).set_index("id")
train_X = data.query("is_train").drop(columns = "is_train")
train_X = tf.convert_to_tensor(train_X)
test_X = data.query("not is_train").drop(columns = "is_train")
test_X = tf.convert_to_tensor(test_X)
random.seed(1337)
model3 = keras.Sequential(
[
Input(shape=(train_X.shape[1],1)),
Conv1D(100, kernel_size=80, activation = "relu"),
Dense(100, activation = "relu"),
Dense(train_Y_one_hot.shape[1], activation="softmax")
]
)
model3.build()
model3.compile(
optimizer=keras.optimizers.SGD(),
loss="categorical_crossentropy",
metrics=[keras.metrics.CategoricalAccuracy(), keras.metrics.TopKCategoricalAccuracy(k=2)]
)
model3.summary()
model3.fit(train_X, train_Y_one_hot, epochs = 100, verbose = 0, validation_data=(test_X, test_Y_one_hot))
model3.evaluate(test_X, test_Y_one_hot)
train_X.shape[1]
import tensorflow as tf
from keras.layers import Conv1D
data = r.c_pitches.merge(r.track_train_test_split).set_index("id")
train_X = data.query("is_train").drop(columns = "is_train")
train_X = tf.convert_to_tensor(train_X)
test_X = data.query("not is_train").drop(columns = "is_train")
test_X = tf.convert_to_tensor(test_X)
random.seed(1337)
model3 = keras.Sequential(
[
Reshape((800, 1), input_shape=(800,))
Conv1D(100, kernel_size=80, activation = "relu"),
Dense(100, activation = "relu"),
Dense(train_Y_one_hot.shape[1], activation="softmax")
]
)
model3.build()
model3.compile(
optimizer=keras.optimizers.SGD(),
loss="categorical_crossentropy",
metrics=[keras.metrics.CategoricalAccuracy(), keras.metrics.TopKCategoricalAccuracy(k=2)]
)
model3.summary()
model3.fit(train_X, train_Y_one_hot, epochs = 100, verbose = 0, validation_data=(test_X, test_Y_one_hot))
model3.evaluate(test_X, test_Y_one_hot)
import tensorflow as tf
from keras.layers import Conv1D
data = r.c_pitches.merge(r.track_train_test_split).set_index("id")
train_X = data.query("is_train").drop(columns = "is_train")
train_X = tf.convert_to_tensor(train_X)
test_X = data.query("not is_train").drop(columns = "is_train")
test_X = tf.convert_to_tensor(test_X)
random.seed(1337)
model3 = keras.Sequential(
[
Reshape((800, 1), input_shape=(800,)),
Conv1D(100, kernel_size=80, activation = "relu"),
Dense(100, activation = "relu"),
Dense(train_Y_one_hot.shape[1], activation="softmax")
]
)
model3.build()
model3.compile(
optimizer=keras.optimizers.SGD(),
loss="categorical_crossentropy",
metrics=[keras.metrics.CategoricalAccuracy(), keras.metrics.TopKCategoricalAccuracy(k=2)]
)
model3.summary()
model3.fit(train_X, train_Y_one_hot, epochs = 100, verbose = 0, validation_data=(test_X, test_Y_one_hot))
model3.evaluate(test_X, test_Y_one_hot)
import tensorflow as tf
from keras.layers import Conv1D, Reshape
data = r.c_pitches.merge(r.track_train_test_split).set_index("id")
train_X = data.query("is_train").drop(columns = "is_train")
train_X = tf.convert_to_tensor(train_X)
test_X = data.query("not is_train").drop(columns = "is_train")
test_X = tf.convert_to_tensor(test_X)
random.seed(1337)
model3 = keras.Sequential(
[
Reshape((800, 1), input_shape=(800,)),
Conv1D(100, kernel_size=80, activation = "relu"),
Dense(100, activation = "relu"),
Dense(train_Y_one_hot.shape[1], activation="softmax")
]
)
model3.build()
model3.compile(
optimizer=keras.optimizers.SGD(),
loss="categorical_crossentropy",
metrics=[keras.metrics.CategoricalAccuracy(), keras.metrics.TopKCategoricalAccuracy(k=2)]
)
model3.summary()
model3.fit(train_X, train_Y_one_hot, epochs = 100, verbose = 0, validation_data=(test_X, test_Y_one_hot))
model3.evaluate(test_X, test_Y_one_hot)
def readucr(filename):
data = np.loadtxt(filename, delimiter="\t")
y = data[:, 0]
x = data[:, 1:]
return x, y.astype(int)
root_url = "https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/"
x_train, y_train = readucr(root_url + "FordA_TRAIN.tsv")
x_test, y_test = readucr(root_url + "FordA_TEST.tsv")
x_test
x_test.shape
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
def readucr(filename):
data = np.loadtxt(filename, delimiter="\t")
y = data[:, 0]
x = data[:, 1:]
return x, y.astype(int)
root_url = "https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/"
x_train, y_train = readucr(root_url + "FordA_TRAIN.tsv")
x_test, y_test = readucr(root_url + "FordA_TEST.tsv")
classes = np.unique(np.concatenate((y_train, y_test), axis=0))
plt.figure()
for c in classes:
c_x_train = x_train[y_train == c]
plt.plot(c_x_train[0], label="class " + str(c))
plt.legend(loc="best")
plt.show()
plt.close()
classes = np.unique(np.concatenate((y_train, y_test), axis=0))
plt.figure()
for c in classes:
c_x_train = x_train[y_train == c]
plt.plot(c_x_train[0], label="class " + str(c))
plt.legend(loc="best")
plt.show()
x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))
x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))
num_classes = len(np.unique(y_train))
idx = np.random.permutation(len(x_train))
x_train = x_train[idx]
y_train = y_train[idx]
y_train[y_train == -1] = 0
y_test[y_test == -1] = 0
x_train
x_train.shape
x_train
x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))
x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))
num_classes = len(np.unique(y_train))
idx = np.random.permutation(len(x_train))
x_train = x_train[idx]
y_train = y_train[idx]
y_train[y_train == -1] = 0
y_test[y_test == -1] = 0
y_test
len(y_test)
x_test.shape
type(x_train)
x_train.shape
y_train.shape
def make_model(input_shape):
input_layer = keras.layers.Input(input_shape)
conv1 = keras.layers.Conv1D(filters=64, kernel_size=3, padding="same")(input_layer)
conv1 = keras.layers.BatchNormalization()(conv1)
conv1 = keras.layers.ReLU()(conv1)
conv2 = keras.layers.Conv1D(filters=64, kernel_size=3, padding="same")(conv1)
conv2 = keras.layers.BatchNormalization()(conv2)
conv2 = keras.layers.ReLU()(conv2)
conv3 = keras.layers.Conv1D(filters=64, kernel_size=3, padding="same")(conv2)
conv3 = keras.layers.BatchNormalization()(conv3)
conv3 = keras.layers.ReLU()(conv3)
gap = keras.layers.GlobalAveragePooling1D()(conv3)
output_layer = keras.layers.Dense(num_classes, activation="softmax")(gap)
return keras.models.Model(inputs=input_layer, outputs=output_layer)
model = make_model(input_shape=x_train.shape[1:])
keras.utils.plot_model(model, show_shapes=True)
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
def readucr(filename):
data = np.loadtxt(filename, delimiter="\t")
y = data[:, 0]
x = data[:, 1:]
return x, y.astype(int)
root_url = "https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/"
x_train, y_train = readucr(root_url + "FordA_TRAIN.tsv")
x_test, y_test = readucr(root_url + "FordA_TEST.tsv")
classes = np.unique(np.concatenate((y_train, y_test), axis=0))
plt.figure()
for c in classes:
c_x_train = x_train[y_train == c]
plt.plot(c_x_train[0], label="class " + str(c))
plt.legend(loc="best")
plt.show()
x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))
x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))
num_classes = len(np.unique(y_train))
idx = np.random.permutation(len(x_train))
x_train = x_train[idx]
y_train = y_train[idx]
y_train[y_train == -1] = 0
y_test[y_test == -1] = 0
x_train.shape
y_train.shape
def make_model(input_shape):
input_layer = keras.layers.Input(input_shape)
conv1 = keras.layers.Conv1D(filters=64, kernel_size=3, padding="same")(input_layer)
conv1 = keras.layers.BatchNormalization()(conv1)
conv1 = keras.layers.ReLU()(conv1)
conv2 = keras.layers.Conv1D(filters=64, kernel_size=3, padding="same")(conv1)
conv2 = keras.layers.BatchNormalization()(conv2)
conv2 = keras.layers.ReLU()(conv2)
conv3 = keras.layers.Conv1D(filters=64, kernel_size=3, padding="same")(conv2)
conv3 = keras.layers.BatchNormalization()(conv3)
conv3 = keras.layers.ReLU()(conv3)
gap = keras.layers.GlobalAveragePooling1D()(conv3)
output_layer = keras.layers.Dense(num_classes, activation="softmax")(gap)
return keras.models.Model(inputs=input_layer, outputs=output_layer)
model = make_model(input_shape=x_train.shape[1:])
keras.utils.plot_model(model, show_shapes=True)
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
import keras
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
def make_model(input_shape):
input_layer = keras.layers.Input(input_shape)
conv1 = keras.layers.Conv1D(filters=64, kernel_size=3, padding="same")(input_layer)
conv1 = keras.layers.BatchNormalization()(conv1)
conv1 = keras.layers.ReLU()(conv1)
conv2 = keras.layers.Conv1D(filters=64, kernel_size=3, padding="same")(conv1)
conv2 = keras.layers.BatchNormalization()(conv2)
conv2 = keras.layers.ReLU()(conv2)
conv3 = keras.layers.Conv1D(filters=64, kernel_size=3, padding="same")(conv2)
conv3 = keras.layers.BatchNormalization()(conv3)
conv3 = keras.layers.ReLU()(conv3)
gap = keras.layers.GlobalAveragePooling1D()(conv3)
output_layer = keras.layers.Dense(num_classes, activation="softmax")(gap)
return keras.models.Model(inputs=input_layer, outputs=output_layer)
model = make_model(input_shape=x_train.shape[1:])
keras.utils.plot_model(model, show_shapes=True)
input_shape=x_train.shape[1:]
input_layer = keras.layers.Input(input_shape)
input_layer
def make_model(input_shape):
input_layer = keras.layers.Input(input_shape)
conv1 = keras.layers.Conv1D(filters=64, kernel_size=3, padding="same")(input_layer)
conv1 = keras.layers.BatchNormalization()(conv1)
conv1 = keras.layers.ReLU()(conv1)
conv2 = keras.layers.Conv1D(filters=64, kernel_size=3, padding="same")(conv1)
conv2 = keras.layers.BatchNormalization()(conv2)
conv2 = keras.layers.ReLU()(conv2)
conv3 = keras.layers.Conv1D(filters=64, kernel_size=3, padding="same")(conv2)
conv3 = keras.layers.BatchNormalization()(conv3)
conv3 = keras.layers.ReLU()(conv3)
gap = keras.layers.GlobalAveragePooling1D()(conv3)
output_layer = keras.layers.Dense(num_classes, activation="softmax")(gap)
return keras.models.Model(inputs=input_layer, outputs=output_layer)
model = make_model(input_shape=x_train.shape[1:])
keras.utils.plot_model(model, show_shapes=True)
tensorboard --logdir logs/fit
x_train
reticulate::repl_python()
